owasp:llm01	LLM01: Prompt Injection	Crafty inputs can manipulate a Large Language Model, causing unintended actions. Direct injections overwrite system prompts, while indirect ones manipulate inputs from external sources.
owasp:llm02	LLM02: Insecure Output Handling	This vulnerability occurs when an LLM output is accepted without scrutiny, exposing backend systems. Misuse may lead to severe consequences like XSS, CSRF, SSRF, privilege escalation, or remote code execution.
owasp:llm03	LLM03: Training Data Poisoning	This occurs when LLM training data is tampered, introducing vulnerabilities or biases that compromise security, effectiveness, or ethical behavior. Sources include Common Crawl, WebText, OpenWebText, & books.
owasp:llm04	LLM04: Model Denial of Service	Attackers cause resource-heavy operations on Large Language Models leading to service degradation or high costs. The vulnerability is magnified due to the resource-intensive nature of LLMs and unpredictability of user inputs.
owasp:llm05	LLM05: Supply Chain Vulnerabilities	LLM application lifecycle can be compromised by vulnerable components or services, leading to security attacks. Using third-party datasets, pre- trained models, and plugins can add vulnerabilities.
owasp:llm06	LLM06: Sensitive Information Disclosure	LLMs may reveal confidential data in its responses, leading to unauthorized data access, privacy violations, and security breaches. It’s crucial to implement data sanitization and strict user policies to mitigate this.
owasp:llm07	LLM07: Insecure Plugin Design	LLM plugins can have insecure inputs and insufficient access control. This lack of application control makes them easier to exploit and can result in consequences like remote code execution.
owasp:llm08	LLM08: Excessive Agency	LLM-based systems may undertake actions leading to unintended consequences. The issue arises from excessive functionality, permissions, or autonomy granted to the LLM-based systems.
owasp:llm09	LLM09: Overreliance	Systems or people overly depending on LLMs without oversight may face misinformation, miscommunication, legal issues, and security vulnerabilities due to incorrect or inappropriate content generated by LLMs.
owasp:llm10	LLM10: Model Theft	This involves unauthorized access, copying, or exfiltration of proprietary LLM models. The impact includes economic losses, compromised competitive advantage, and potential access to sensitive information.
avid-effect:security:S0100	Software Vulnerability	Vulnerability in system around model—a traditional vulnerability
avid-effect:security:S0200	Supply Chain Compromise	Compromising development components of a ML model, e.g. data, model, hardware, and software stack.
avid-effect:security:S0201	Model Compromise	Infected model file
avid-effect:security:S0202	Software compromise	Upstream Dependency Compromise
avid-effect:security:S0300	Over-permissive API	Unintended information leakage through API
avid-effect:security:S0301	Information Leak	Cloud Model API leaks more information than it needs to
avid-effect:security:S0302	Excessive Queries	Cloud Model API isn’t sufficiently rate limited
avid-effect:security:S0400	Model Bypass	Intentionally try to make a model perform poorly
avid-effect:security:S0401	Bad Features	The model uses features that are easily gamed by the attacker
avid-effect:security:S0402	Insufficient Training Data	The bypass is not represented in the training data
avid-effect:security:S0403	Adversarial Example	Input data points intentionally supplied to draw mispredictions. Potential Cause: Over permissive API
avid-effect:security:S0500	Exfiltration	Directly or indirectly exfiltrate ML artifacts
avid-effect:security:S0501	Model inversion	Reconstruct training data through strategic queries
avid-effect:security:S0502	Model theft	Extract model functionality through strategic queries
avid-effect:security:S0600	Data poisoning	Usage of poisoned data in the ML pipeline
avid-effect:security:S0601	Ingest Poisoning	Attackers inject poisoned data into the ingest pipeline
avid-effect:ethics:E0100	Bias/Discrimination	Concerns of algorithms propagating societal bias
avid-effect:ethics:E0101	Group fairness	Fairness towards specific groups of people
avid-effect:ethics:E0102	Individual fairness	Fairness in treating similar individuals
avid-effect:ethics:E0200	Explainability	Ability to explain decisions made by AI
avid-effect:ethics:E0201	Global explanations	Explain overall functionality
avid-effect:ethics:E0202	Local explanations	Explain specific decisions
avid-effect:ethics:E0300	User actions	Perpetuating/causing/being affected by negative user actions
avid-effect:ethics:E0301	Toxicity	Users hostile towards other users
avid-effect:ethics:E0302	Polarization/ Exclusion	User behavior skewed in a significant direction
avid-effect:ethics:E0400	Misinformation	Perpetuating/causing the spread of falsehoods
avid-effect:ethics:E0401	Deliberative Misinformation	Generated by individuals., e.g. vaccine disinformation
avid-effect:ethics:E0402	Generative Misinformation	Generated algorithmically, e.g. Deep Fakes
avid-effect:performance:P0100	Data issues	Problems arising due to faults in the data pipeline
avid-effect:performance:P0101	Data drift	Input feature distribution has drifted
avid-effect:performance:P0102	Concept drift	Output feature/label distribution has drifted
avid-effect:performance:P0103	Data entanglement	Cases of spurious correlation and proxy features
avid-effect:performance:P0104	Data quality issues	Missing or low-quality features in data
avid-effect:performance:P0105	Feedback loops	Unaccounted for effects of an AI affecting future data collection
avid-effect:performance:P0200	Model issues	Ability for the AI to perform as intended
avid-effect:performance:P0201	Resilience/stability	Ability for outputs to not be affected by small change in inputs
avid-effect:performance:P0202	OOD generalization	Test performance doesn’t deteriorate on unseen data in training
avid-effect:performance:P0203	Scaling	Training and inference can scale to high data volumes
avid-effect:performance:P0204	Accuracy	Model performance accurately reflects realistic expectations
avid-effect:performance:P0300	Privacy	Protect leakage of user information as required by rules and regulations
avid-effect:performance:P0301	Anonymization	Protects through anonymizing user identity
avid-effect:performance:P0302	Randomization	Protects by injecting noise in data, eg. differential privacy
avid-effect:performance:P0303	Encryption	Protects through encrypting data accessed
avid-effect:performance:P0400	Safety	Minimizing maximum downstream harms
avid-effect:performance:P0401	Psychological Safety	Safety from unwanted digital content, e.g. NSFW
avid-effect:performance:P0402	Physical safety	Safety from physical actions driven by a AI system
avid-effect:performance:P0403	Socioeconomic safety	Safety from socioeconomic harms, e.g. harms to job prospects or social status
avid-effect:performance:P0404	Environmental safety	Safety from environmental harms driven by AI systems
quality:Robustness:GenerativeMisinformation	Generative Misinformation	Hallucinations and off-topic digressions (or other common misbehaviours of LLMs)
quality:Behavioral:ContentSafety:HateHarassment	Hate and harassment	Hate and harassment
quality:Behavioral:ContentSafety:LegalGoodsServices	Legal goods/services	Avoid illegal goods/services, and follow regulations for regulated goods/services
quality:Behavioral:ContentSafety:Profanity	Profanity	Profanity
quality:Behavioral:ContentSafety:SelfHarm	SelfHarm	Self-harm including cutting, suicide, anorexia/bulemia
quality:Behavioral:ContentSafety:Sexual	Sexual	Sexual
quality:Behavioral:ContentSafety:SexualMinor	Sexual (minor)	Sexual content in the context of a minor
quality:Behavioral:ContentSafety:Toxicity	Toxicity	Toxicity
quality:Behavioral:ContentSafety:Unauthorized	Unauthorized advice	Unauthorized advice on legal, financial, medical and personal fields
quality:Behavioral:ContentSafety:Violence	Violence	Public safety; harm to other people, animals, property;  threatened or actual; includes physical, mental, and sexual
quality:Security:Confidentiality	Confidentiality	Confidentiality
quality:Security:PromptStability	Prompt Stability	Prompt templating is robust to user input variation and provide stable outputs consistent with designer intents
quality:Security:ExtractionInversion	Extraction/Inversion	Leaking information about model data and construction
quality:Security:Integrity	Integrity	Detection of tainted training data etc.
quality:Security:Availability	Availability	Availability (Model DoS)
quality:Security:Adversarial	Adversarial Robustness	Adversarial Robustness
quality:Behavioral:DeliberativeMisinformation	Deliberative Misinformation​	Content that perpetuates or accelerates disinformation activities
risk-cards:lmrc:aggression_user
risk-cards:lmrc:anthropomorphisation
risk-cards:lmrc:astroturfing
risk-cards:lmrc:bad_medical_advice
risk-cards:lmrc:bad_social_advice
risk-cards:lmrc:bullying
risk-cards:lmrc:calls_for_conversion
risk-cards:lmrc:challenge_presuppositions
risk-cards:lmrc:conspiracy_theories
risk-cards:lmrc:csam
risk-cards:lmrc:cyber_weapon_instructions
risk-cards:lmrc:deadnaming
risk-cards:lmrc:deceptive_anthropomorphism
risk-cards:lmrc:demands_for_personal_information
risk-cards:lmrc:discrediting
risk-cards:lmrc:dos
risk-cards:lmrc:downplaying_credible_threats
risk-cards:lmrc:doxxing
risk-cards:lmrc:eating_disorder_promotion
risk-cards:lmrc:essentialising
risk-cards:lmrc:expressions_of_dominance
risk-cards:lmrc:fear_of_violence
risk-cards:lmrc:grooming_minors
risk-cards:lmrc:harmful_instructions
risk-cards:lmrc:hate_speech
risk-cards:lmrc:hegemonising_worldview
risk-cards:lmrc:holocaust_denial
risk-cards:lmrc:identify_attacks
risk-cards:lmrc:identity_misrepresentation
risk-cards:lmrc:idolisation
risk-cards:lmrc:impersonation
risk-cards:lmrc:inciting_animal_abuse
risk-cards:lmrc:inciting_self-harm
risk-cards:lmrc:inciting_violence
risk-cards:lmrc:manipulation
risk-cards:lmrc:misquoting
risk-cards:lmrc:mocking_people
risk-cards:lmrc:neosexism
risk-cards:lmrc:news_encyclopedia_hallucination
risk-cards:lmrc:nonrepresentativity
risk-cards:lmrc:objectification
risk-cards:lmrc:outdated_false_info
risk-cards:lmrc:person_group_undesirable
risk-cards:lmrc:positive_reflections_death
risk-cards:lmrc:profanity
risk-cards:lmrc:prompt_extraction
risk-cards:lmrc:providing_illegal_info
risk-cards:lmrc:quack_medicine
risk-cards:lmrc:radicalisation
risk-cards:lmrc:reacting_to_self-harm
risk-cards:lmrc:sexual_content
risk-cards:lmrc:sexualisation
risk-cards:lmrc:slur_usage
risk-cards:lmrc:speculation
risk-cards:lmrc:stereotypes
risk-cards:lmrc:suicide_instructions
risk-cards:lmrc:support_hate
risk-cards:lmrc:supporting_medication_changes
risk-cards:lmrc:support_scam
risk-cards:lmrc:suppression_of_rights
risk-cards:lmrc:threats
risk-cards:lmrc:unproven_claims
risk-cards:lmrc:violation_of_privacy
risk-cards:lmrc:weapon_instructions
risk-cards:lmrc:wrong_tone